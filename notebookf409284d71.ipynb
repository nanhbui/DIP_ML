{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1118216,"sourceType":"datasetVersion","datasetId":627736},{"sourceId":10179289,"sourceType":"datasetVersion","datasetId":6287659},{"sourceId":10373010,"sourceType":"datasetVersion","datasetId":6425456},{"sourceId":220788,"sourceType":"modelInstanceVersion","modelInstanceId":188300,"modelId":210327},{"sourceId":220874,"sourceType":"modelInstanceVersion","modelInstanceId":188376,"modelId":210403}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHẠY TỪNG CÁI KHÔNG ĐƯỢC RUN ALL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torchvision import transforms\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils import spectral_norm\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.metrics import structural_similarity as ssim\nfrom math import log10\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T13:21:49.686651Z","iopub.execute_input":"2025-01-07T13:21:49.686989Z","iopub.status.idle":"2025-01-07T13:21:56.658562Z","shell.execute_reply.started":"2025-01-07T13:21:49.68695Z","shell.execute_reply":"2025-01-07T13:21:56.657502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check cuda\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available. Using CUDA!\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available. Using CPU!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T13:21:56.668245Z","iopub.execute_input":"2025-01-07T13:21:56.668773Z","iopub.status.idle":"2025-01-07T13:21:56.767459Z","shell.execute_reply.started":"2025-01-07T13:21:56.668735Z","shell.execute_reply":"2025-01-07T13:21:56.766378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#metrics\ndef calculate_psnr(img1, img2):\n    mse = np.mean((img1 - img2) ** 2)\n    if mse == 0:\n        return 100\n    return 20 * log10(1.0 / np.sqrt(mse))\n\ndef calculate_ssim(img1, img2):\n    return ssim(img1, img2, multichannel=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T13:21:59.840291Z","iopub.execute_input":"2025-01-07T13:21:59.841212Z","iopub.status.idle":"2025-01-07T13:21:59.846849Z","shell.execute_reply.started":"2025-01-07T13:21:59.841163Z","shell.execute_reply":"2025-01-07T13:21:59.84607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#utils\ndef save_model(model, path):\n    torch.save(model.state_dict(), path)\n\ndef load_model(model, path, device):\n    model.load_state_dict(torch.load(path, map_location=device,weights_only=True))\n    return model\n\ndef display_images(images, titles=None):\n    n = len(images)\n    plt.figure(figsize=(15, 5))\n    for i, img in enumerate(images):\n        plt.subplot(1, n, i+1)\n        plt.imshow(img.permute(1, 2, 0).cpu().numpy())\n        if titles:\n            plt.title(titles[i])\n        plt.axis('off')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T13:22:02.040122Z","iopub.execute_input":"2025-01-07T13:22:02.040424Z","iopub.status.idle":"2025-01-07T13:22:02.046231Z","shell.execute_reply.started":"2025-01-07T13:22:02.040399Z","shell.execute_reply":"2025-01-07T13:22:02.045383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#datasets\nclass DeblurDataset(Dataset):\n    def __init__(self, blur_dir, sharp_dir, transform=None):\n        self.blur_dir = blur_dir\n        self.sharp_dir = sharp_dir\n        self.blur_images = sorted(os.listdir(blur_dir))\n        self.sharp_images = sorted(os.listdir(sharp_dir))\n        self.transform = transform or transforms.Compose([\n            transforms.Resize((360,640)),\n            transforms.ToTensor()\n        ])\n\n    def __len__(self):\n        return len(self.blur_images)\n\n    def __getitem__(self, idx):\n        blur_path = os.path.join(self.blur_dir, self.blur_images[idx])\n        sharp_path = os.path.join(self.sharp_dir, self.sharp_images[idx])\n\n        blur_img = Image.open(blur_path).convert(\"RGB\")\n        sharp_img = Image.open(sharp_path).convert(\"RGB\")\n\n        if self.transform:\n            blur_img = self.transform(blur_img)\n            sharp_img = self.transform(sharp_img)\n\n        return blur_img, sharp_img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T13:22:04.744674Z","iopub.execute_input":"2025-01-07T13:22:04.74536Z","iopub.status.idle":"2025-01-07T13:22:04.751472Z","shell.execute_reply.started":"2025-01-07T13:22:04.745327Z","shell.execute_reply":"2025-01-07T13:22:04.750593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super(ResidualBlock, self).__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(channels),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\n\nclass Generator(nn.Module):\n    def __init__(self, num_residual_blocks=6):\n        super(Generator, self).__init__()\n\n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n        )\n\n        # Bottleneck with residual blocks\n        self.bottleneck = nn.Sequential(\n            *[ResidualBlock(256) for _ in range(num_residual_blocks)]\n        )\n\n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=3),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        # Pass through encoder\n        encoded = self.encoder(x)\n\n        # Pass through bottleneck with residual blocks\n        bottleneck = self.bottleneck(encoded)\n\n        # Decode to reconstruct the image\n        decoded = self.decoder(bottleneck)\n        return decoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T13:22:07.056027Z","iopub.execute_input":"2025-01-07T13:22:07.056352Z","iopub.status.idle":"2025-01-07T13:22:07.065467Z","shell.execute_reply.started":"2025-01-07T13:22:07.056324Z","shell.execute_reply":"2025-01-07T13:22:07.064618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.model = nn.Sequential(\n            # Input: (B, 3, H, W)\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # Downsample\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # Downsample\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # Downsample\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),  # Downsample\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),  # Final classification\n            nn.Sigmoid()  # Output: Validity score\n        )\n\n    def forward(self, img):\n        validity = self.model(img)  # Output shape: (B, 1, 1, 1)\n        return validity.view(-1, 1)  # Flatten to (B, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T13:22:10.144761Z","iopub.execute_input":"2025-01-07T13:22:10.145105Z","iopub.status.idle":"2025-01-07T13:22:10.151971Z","shell.execute_reply.started":"2025-01-07T13:22:10.145076Z","shell.execute_reply":"2025-01-07T13:22:10.151073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Khởi tạo mô hình\ngenerator = Generator().to(device)  # Sử dụng lớp Generator đã định nghĩa\ndiscriminator = Discriminator().to(device)  # Sử dụng lớp Discriminator đã định nghĩa\n\n# Dataset và DataLoader\ntrain_dataset = DeblurDataset(\"/kaggle/input/gopro-deblur/gopro_deblur/blur/images\", \"/kaggle/input/gopro-deblur/gopro_deblur/sharp/images\")\ntrain_loader = DataLoader(train_dataset, batch_size=6, shuffle=True)\nval_dataset = DeblurDataset(\"/kaggle/input/validation/val/blur\", \"/kaggle/input/validation/val/sharp\")\nval_loader = DataLoader(val_dataset, batch_size=6, shuffle=False)\n\n# Hàm mất mát\nadversarial_loss = nn.BCEWithLogitsLoss()  # Sử dụng BCE với logits cho đầu ra từ discriminator\npixel_loss = nn.L1Loss()  # Mất mát theo pixel (L1)\n\n# Optimizer\ng_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\nd_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\n# Theo dõi checkpoint tốt nhất\nbest_val_loss = float('inf')  # Khởi tạo giá trị rất lớn\nbest_checkpoint = None\n\n# Danh sách lưu loss để vẽ biểu đồ\ntraining_losses = []\nvalidation_losses = []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T13:22:12.984197Z","iopub.execute_input":"2025-01-07T13:22:12.984849Z","iopub.status.idle":"2025-01-07T13:22:13.589821Z","shell.execute_reply.started":"2025-01-07T13:22:12.984819Z","shell.execute_reply":"2025-01-07T13:22:13.589169Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vòng lặp huấn luyện\nnum_epochs = 80\nbest_val_loss = float('inf')  # Giá trị khởi tạo cho loss tốt nhất\ntraining_losses = []  # Danh sách lưu training loss\nvalidation_losses = []  # Danh sách lưu validation loss\n\nfor epoch in range(num_epochs):\n    generator.train()\n    train_loss = 0  # Tổng loss cho epoch hiện tại\n    for i, (blurred, sharp) in enumerate(train_loader):\n        blurred, sharp = blurred.to(device), sharp.to(device)\n        \n        # ====== 1. Huấn luyện Discriminator ======\n        \n        real_output = discriminator(sharp)\n        fake_images = generator(blurred)\n        fake_output = discriminator(fake_images.detach())\n        real_labels = torch.ones_like(real_output, device=device)\n        fake_labels = torch.zeros_like(fake_output, device=device)\n        d_optimizer.zero_grad()\n        real_loss = adversarial_loss(real_output, real_labels)\n        fake_loss = adversarial_loss(fake_output, fake_labels)\n        d_loss = (real_loss + fake_loss) / 2\n        d_loss.backward()\n        d_optimizer.step()\n        \n        # ====== 2. Huấn luyện Generator ======\n        \n        g_optimizer.zero_grad()\n        fake_output = discriminator(fake_images)\n        real_labels = torch.ones_like(fake_output, device=device)\n        g_adv_loss = adversarial_loss(fake_output, real_labels)\n        g_pix_loss = pixel_loss(fake_images, sharp)\n        g_loss = g_adv_loss + 100 * g_pix_loss\n        g_loss.backward()\n        g_optimizer.step()\n        \n        train_loss += g_loss.item()\n        \n        # Hiển thị log sau mỗi 10 bước\n        if i % 5 == 0:\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], \"\n                  f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n\n    # Tính toán và lưu training loss cho epoch hiện tại\n    training_losses.append(train_loss / len(train_loader))\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss / len(train_loader):.4f}\")\n\n    # Validation sau mỗi epoch\n    generator.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for blurred, sharp in val_loader:\n            blurred, sharp = blurred.to(device), sharp.to(device)\n            fake_images = generator(blurred)\n            val_loss += pixel_loss(fake_images, sharp).item()\n    \n    val_loss /= len(val_loader)\n    validation_losses.append(val_loss)  # Lưu validation loss cho epoch hiện tại\n    print(f\"Epoch [{epoch+1}/{num_epochs}] Validation Loss: {val_loss:.4f}\")\n\n    # Lưu checkpoint cho mỗi epoch\n    checkpoint_generator = f\"/kaggle/working/generatorepoch{epoch+1}.pth\"\n    save_model(generator, checkpoint_generator)\n\n    # Kiểm tra và cập nhật loss tốt nhất\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_checkpoint_generator = checkpoint_generator\n\n# Hoàn tất huấn luyện\nprint(\"Training complete!\")\nprint(f\"Best generator checkpoint: {best_checkpoint_generator} with Validation Loss: {best_val_loss:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== Vẽ biểu đồ loss =====\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, num_epochs + 1), training_losses, label=\"Training Loss\")\nplt.plot(range(1, num_epochs + 1), validation_losses, label=\"Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training vs Validation Loss\")\nplt.legend()\nplt.grid()\nplt.savefig(f\"loss_plot.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load mô hình\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngenerator = Generator().to(device)  \ngenerator = load_model(generator,\"/kaggle/input/finalmodel/pytorch/default/1/generatorepoch74.pth\", device)\n\n# Tiền xử lý ảnh\ntransform = transforms.Compose([\n    transforms.Resize((360,640)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Dự đoán\nimg = Image.open(\"/kaggle/input/test-data/test/blur/310.png\").convert(\"RGB\")\ninput_tensor = transform(img).unsqueeze(0).to(device)\n\nwith torch.no_grad():\n    output_tensor = generator(input_tensor)\n\n# Lưu hoặc hiển thị ảnh kết quả\noutput_img = transforms.ToPILImage()(output_tensor.squeeze().cpu())\noutput_img.save(\"output(310).png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T13:36:36.84368Z","iopub.execute_input":"2025-01-07T13:36:36.844058Z","iopub.status.idle":"2025-01-07T13:36:37.31137Z","shell.execute_reply.started":"2025-01-07T13:36:36.844025Z","shell.execute_reply":"2025-01-07T13:36:37.310479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load mô hình\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngenerator = Generator().to(device)\n\n# Hàm load model\ndef load_model(model, path, device):\n    state_dict = torch.load(path, map_location=device, weights_only=True)\n    model.load_state_dict(state_dict)\n    model.eval()\n    return model\n\n# Hàm tính PSNR\ndef calculate_psnr(img1, img2):\n    mse = np.mean((img1 - img2) ** 2)\n    if mse == 0:\n        return float('inf')\n    max_pixel = 1.0\n    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n    return psnr\n\n# Hàm tính SSIM\ndef calculate_ssim(img1, img2, win_size=7):\n    return ssim(img1, img2, \n               channel_axis=2,\n               win_size=win_size, \n               data_range=1.0)\n\n# Load model\ngenerator = load_model(generator, \"/kaggle/input/finalmodel/pytorch/default/1/generatorepoch74.pth\", device)\n\n# Dataset và DataLoader\ntest_dataset = DeblurDataset(\"/kaggle/input/test-data/test/blur\", \"/kaggle/input/test-data/test/sharp\")\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# Biến lưu tổng PSNR, SSIM và số lượng ảnh\ntotal_psnr = 0.0\ntotal_ssim = 0.0\ncount = 0\n\n# Đánh giá\nfor blurred, sharp in test_loader:\n    blurred = blurred.to(device)\n    sharp = sharp.to(device)\n    \n    # Sinh ảnh\n    with torch.no_grad():\n        output = generator(blurred)\n    \n    # Tính PSNR và SSIM\n    output_resized = np.transpose(output.cpu().numpy()[0], (1, 2, 0))\n    sharp_resized = np.transpose(sharp.cpu().numpy()[0], (1, 2, 0))\n    output_resized = np.clip(output_resized, 0, 1)\n    sharp_resized = np.clip(sharp_resized, 0, 1)\n    \n    psnr_val = calculate_psnr(output_resized, sharp_resized)\n    min_dim = min(output_resized.shape[0], output_resized.shape[1])\n    win_size = min(11, min_dim - (min_dim % 2) + 1)\n    ssim_val = calculate_ssim(output_resized, sharp_resized, win_size=win_size)\n    \n    # Cộng dồn giá trị PSNR và SSIM\n    total_psnr += psnr_val\n    total_ssim += ssim_val\n    count += 1\n    \n    # In PSNR và SSIM cho từng ảnh\n    print(f\"PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f}\")\n    print(\"-\" * 50)\n\n# Tính trung bình PSNR và SSIM\navg_psnr = total_psnr / count\navg_ssim = total_ssim / count\n\n# In trung bình PSNR và SSIM\nprint(f\"Average PSNR: {avg_psnr:.2f}\")\nprint(f\"Average SSIM: {avg_ssim:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install xlsxwriter","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\n\n# Chuyển kết quả thành DataFrame\ndf = pd.DataFrame(results)\n\n# Lưu dữ liệu và tạo charts trong Excel sử dụng XlsxWriter\nwith pd.ExcelWriter('deblur_results.xlsx', engine='xlsxwriter') as writer:\n    # Sheet dữ liệu chi tiết\n    df.to_excel(writer, sheet_name='Detailed Results', index=False)\n    \n    # Sheet thống kê\n    stats = pd.DataFrame({\n        'Metric': ['PSNR', 'SSIM'],\n        'Mean': [df['PSNR'].mean(), df['SSIM'].mean()],\n        'Std': [df['PSNR'].std(), df['SSIM'].std()],\n        'Min': [df['PSNR'].min(), df['SSIM'].min()],\n        'Max': [df['PSNR'].max(), df['SSIM'].max()]\n    })\n    stats.to_excel(writer, sheet_name='Statistics', index=False)\n    \n    # Lấy workbook và worksheet để tạo charts\n    workbook = writer.book\n    worksheet = writer.sheets['Detailed Results']\n    \n    # Tạo chart cho PSNR\n    chart_psnr = workbook.add_chart({'type': 'line'})\n    chart_psnr.add_series({\n        'name': 'PSNR',\n        'categories': ['Detailed Results', 1, 0, len(df), 0],\n        'values': ['Detailed Results', 1, 1, len(df), 1],\n        'marker': {'type': 'circle'},\n    })\n    chart_psnr.set_title({'name': 'PSNR Values Across Images'})\n    chart_psnr.set_x_axis({'name': 'Image'})\n    chart_psnr.set_y_axis({'name': 'PSNR'})\n    worksheet.insert_chart('H2', chart_psnr)\n    \n    # Tạo chart cho SSIM\n    chart_ssim = workbook.add_chart({'type': 'line'})\n    chart_ssim.add_series({\n        'name': 'SSIM',\n        'categories': ['Detailed Results', 1, 0, len(df), 0],\n        'values': ['Detailed Results', 1, 2, len(df), 2],\n        'marker': {'type': 'circle'},\n        'line': {'color': 'red'},\n    })\n    chart_ssim.set_title({'name': 'SSIM Values Across Images'})\n    chart_ssim.set_x_axis({'name': 'Image'})\n    chart_ssim.set_y_axis({'name': 'SSIM'})\n    worksheet.insert_chart('H18', chart_ssim)\n\n# Vẽ biểu đồ bằng matplotlib\nplt.figure(figsize=(15, 10))\n\n# PSNR plot\nplt.subplot(2, 1, 1)\nsns.lineplot(data=df, x='Image', y='PSNR', marker='o')\nplt.title('PSNR Values Across Images')\nplt.xticks(rotation=45)\nplt.grid(True)\n\n# SSIM plot\nplt.subplot(2, 1, 2)\nsns.lineplot(data=df, x='Image', y='SSIM', marker='o', color='red')\nplt.title('SSIM Values Across Images')\nplt.xticks(rotation=45)\nplt.grid(True)\n\nplt.tight_layout()\nplt.savefig('metrics_plots.png', dpi=300, bbox_inches='tight')\nplt.close()\n\n# In thống kê tổng quát\nprint(\"\\nThống kê tổng quát:\")\nprint(stats.to_string(index=False))\n\n# In giá trị trung bình\nprint(f\"\\nGiá trị trung bình:\")\nprint(f\"PSNR trung bình: {df['PSNR'].mean():.2f}\")\nprint(f\"SSIM trung bình: {df['SSIM'].mean():.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}